#*****************************************************************************************
# Manuscript: "Influence of intermittent stream dynamics on predator-prey interactions"
# 1*Milena Gonçalves-Silva, 2Elvira D’Bastiani, 3Thibault Datry, 1Carla Ferreira Rezende
# 1Programa de Pós-Graduação em Ecologia e Recursos Naturais, Universidade Federal do Ceará, Brasil.
# 2Department of Ecology and Evolutionary Biology, University of California, Los Angeles, USA.
# 3INRAE, UR RiverLy, Centre de Lyon-Villeurbanne, Villeurbanne, France.
# *Corresponding author: Milena Gonçalves-Silva, e-mail: milenagoncalves.bio@gmail.com
# Script created by: Elvira D’Bastiani
#*****************************************************************************************

#Citation: Gonçalves-Silva, M., D’Bastiani, E., Datry, T., & Rezende, C. F. (Year). Influence of intermittent stream dynamics on predator-prey interactions. Journal of [Journal Name], [Year], [Volume(Issue)], [Page Range]. DOI: [DOI Number].

#########################################################################################################################################
#########################################################################################################################################
#Question: (ii) Do hydrological phases in intermittent streams affect predator-prey network structures? 
#          (iii) Do stochastic factors during the dry phase affect predator-prey network structures?
#########################################################################################################################################
#########################################################################################################################################

# Setup 
#To remove all objects stored in the current workspace
rm(list=ls())

#To clean up the garbage collection in R, you can use the gc() function:
gc()

# Directory
setwd()

# Install and load the Factoshiny package
install.packages(c("bipartite", "ggplot2",
                   "igraph", "viridis", "performance"))
library("bipartite")
library("ggplot2")
library("igraph")
library("viridis")
library("performance")

# Function to compute metrics and normalize them
metrics_norm <- function(matriz, nran) {
  # Generate null models
  null_model <- nullmodel(matriz, N = nran, method = "vaznull")
  
  # Data frames to store metrics
  metricas_nulas <- data.frame(nestedness = as.numeric(),
                               specialization = as.numeric(),
                               modularity = as.numeric())
  
  # Output data frame
  output <- data.frame(Nprey = as.numeric(),
                       Npredator = as.numeric(),
                       nestedness = as.numeric(),
                       specialization = as.numeric(),
                       modularity = as.numeric(),
                       zs_nestedness = as.numeric(),
                       zs_specialization = as.numeric(),
                       zs_modularity = as.numeric(),
                       dif_nestedness = as.numeric(),
                       dif_specialization = as.numeric(),
                       dif_modularity = as.numeric())
  
  # Compute metrics for null models
  for(i in 1:length(null_model)){
    metricas_nulas[i, ] <- NA
    metricas_nulas$nestedness[i] <- nested(null_model[[i]], method = "NODF2", rescale = FALSE) / 100
    
    specialization_nulas <- H2fun(null_model[[i]], F)
    metricas_nulas$specialization[i] <- specialization_nulas[1]
    
    m <- graph_from_incidence_matrix(null_model[[i]])
    lou <- cluster_louvain(m)
    metricas_nulas$modularity[i] <- modularity(lou)
  }
  
  # Compute metrics for original matrix
  Nprey <- sum(ncol(matriz))
  Npredator <- sum(nrow(matriz))
  
  nestedness_sim <- nested(matriz, method = "NODF2", rescale = FALSE) / 100
  zs_nestedness <- (nestedness_sim - mean(metricas_nulas$nestedness)) / sd(metricas_nulas$nestedness)
  
  specialization_s <- H2fun(matriz, F)
  specialization_sim <- specialization_s[1]
  zs_specialization <- (specialization_sim - mean(metricas_nulas$specialization)) / sd(metricas_nulas$specialization)
  
  m_s <- graph_from_incidence_matrix(matriz)
  lou_s <- cluster_louvain(m_s)
  modularity_sim <- modularity(lou_s)
  zs_modularity <- (modularity_sim - mean(metricas_nulas$modularity)) / sd(metricas_nulas$modularity)
  
  dif_nestedness <- (nestedness_sim - mean(metricas_nulas$nestedness))
  dif_specialization <- (specialization_sim - mean(metricas_nulas$specialization))
  dif_modularity <- (modularity_sim - mean(metricas_nulas$modularity))
  
  output[1, ] <- c(Nprey, Npredator, nestedness_sim, specialization_sim,
                   modularity_sim, zs_nestedness, zs_specialization,
                   zs_modularity, dif_nestedness, dif_specialization, dif_modularity)
  
  return(output)
}

# Read the network data
net_flowing <- read.csv("fooditems_flowing.csv", sep = ";", row.names = 1, dec = ".")

# Convert networks to matrices
net_flowing <- as.matrix(net_flowing)

# Remove non-interacting species
net_flowing <- net_flowing[, !!colSums(net_flowing)]
net_flowing <- net_flowing[!!rowSums(net_flowing),]

# Compute and extract specialization, nestedness, and modularity metrics
specialization_flowing <- H2fun(net_flowing, F)
nestedness_flowing <- nested(net_flowing, method = "NODF2", rescale = FALSE) / 100
g_flowing <- graph_from_incidence_matrix(net_flowing)
clu_louvg_flowing <- cluster_louvain(g_flowing)
modularity_flowing <- modularity(clu_louvg_flowing)

# Compute null model and normalization
results_norm_flowing <- metrics_norm(net_flowing, 1000)

# Process and write results to CSV
write.csv(results_norm_flowing, "results_norm_flowing.csv")

# Number of pools
total_de_poll <- 22

# Loop through each pool network
output <- NULL
for (n in 1:total_de_poll) {
  net_dry <- read.csv2(paste0("P", n, ".csv"), sep = ";", row.names = 1, dec = ".")
  net_dry <- as.matrix(net_dry)
  net_dry <- net_dry[, !!colSums(net_dry)]
  net_dry <- net_dry[!!rowSums(net_dry),]
  
  specialization_dry <- H2fun(net_dry, F)
  nestedness_dry <- nested(net_dry, method = "NODF2", rescale = FALSE) / 100
  g_dry <- graph_from_incidence_matrix(net_dry)
  clu_louvg_dry <- cluster_louvain(g_dry)
  modularity_dry <- modularity(clu_louvg_dry)
  
  results_norm_dry <- metrics_norm(net_dry, 1000)
  
  if (n == 1) {
    output <- c(n, results_norm_dry)
  } else {
    outputb <- c(n, results_norm_dry)
    output <- rbind(output, outputb)
  }
}

# Organize and write results to CSV
output <- as.data.frame(output)
colnames(output)[1] <- "pool"
write.csv(as.matrix(output), "results_norm_dry.csv")

##########################################################################################
############Script - Theoretical model based on observed predator richness 
##########################################################################################

#number of pools
total_poll <- 22

# here just to start at pool network 1
n_network = 0

for (n_network in 1:total_poll) {  # here I renamed your networks as: network_1, network_2, network_3....
  #inform:
  n_amostral = 1000
  #load the data
  all_poll <- read.csv2("fooditems_flowing.csv", header=TRUE)  # here goes the full network
  sampling_poll <- read.csv2(paste0("P", n_network, ".csv"), header=TRUE)  # each pool
  
  #define the names of the network files' rows
  row.names(all_poll) = all_poll[,1]
  row.names(sampling_poll) = sampling_poll[,1]
  
  #convert networks to matrix
  all_poll = as.matrix(all_poll[, 2:ncol(all_poll)])
  sampling_poll = as.matrix(sampling_poll[, 2:ncol(sampling_poll)])
  
  #Convert character elements to numeric
  all_poll_numeric <- array(as.numeric(all_poll), dim = dim(all_poll))
  sampling_poll_numeric <- array(as.numeric(sampling_poll), dim = dim(sampling_poll))
  #Set the same format and names
  dimnames(all_poll_numeric) <- dimnames(all_poll)
  dimnames(sampling_poll_numeric) <- dimnames(sampling_poll)
  
  #now here we are preparing to sample the random networks, so we will use the all_poll network for the sampling_poll
  
  #change the object name
  all_poll <- all_poll_numeric
  dimnames(all_poll) <- dimnames(all_poll_numeric)
  
  net_poll <- sampling_poll_numeric
  dimnames(net_poll) <- dimnames(sampling_poll_numeric)
  
  #First we need to know the number of predators and the number of preys
  #number of predators
  predator_obs = nrow(net_poll)
  #number of preys
  prey_obs = ncol(net_poll)
  
  #nestedness
  #NODF_obs = nested(net_poll, method = "NODF2", rescale = FALSE, normalised = TRUE)
  NODF_obs = nested(net_poll, method = "NODF2", rescale = FALSE) / 100
  NODF_obs = round(NODF_obs, digits = 3)

  #specialization
  specialization_o <- H2fun(net_poll, F)
  speci_o <- as.data.frame(specialization_o)
  Specialization_obs <- speci_o$specialization_o

  #modularity
  m = graph_from_incidence_matrix(net_poll)
  louvain <- cluster_louvain(m)
  Modularidade_obs = modularity(louvain)
  
  #define the number of predator species (predator richness) you have in the pool you are going to analyze
  nl = nrow(net_poll)
  nc = ncol(net_poll)
  
  for (n in 1:n_amostral) {
    sub = all_poll
    
    while (nrow(sub) > nrow(net_poll)) {
      #remove the predators
      ls = floor(runif(1, 1, nrow(sub) + 1))
      #define the new sub network
      sub = sub[-ls,]
      
      # sub = sub[, !!colSums(sub)] #eliminate those that do not interact
      # sub = sub[!!rowSums(sub),]
      
      # Eliminate rows and columns with all zeros
      sub <- sub[, colSums(sub) > 0]
      sub <- sub[rowSums(sub) > 0,]
      
    }
    #save each subnet
    nome <- paste0("poll_", n_network, "_subnet_", n, ".txt", sep = " ")
    write.table(sub, nome, col.names = NA, row.names = T, sep = "\t")
    
    #now let's calculate the network metrics
    #number of predators
    predator_sub = nrow(sub)
    #number of prey
    prey_sub = ncol(sub)
    
    #nestedness
    NODF_sub = nested(sub, method = "NODF2", rescale = FALSE) / 100
    NODF_sub = round(NODF_sub, digits = 3)

    #specialization
    specialization_s <- H2fun(sub, F)
    speci_s <- as.data.frame(specialization_s)
    Specialization_sub <- speci_s$specialization_s

    #modularity
    m_sub = graph_from_incidence_matrix(sub)
    louvain_sub <- cluster_louvain(m_sub)
    Modularidade_sub = modularity(louvain_sub)
    
    #here you can also include the h2 index if you want
    
    if (n == 1) {
      output = c(n_network,  #which pool are you analyzing
                n,  #which simulated subnetwork
                predator_obs,
                prey_obs,
                NODF_obs,
                Specialization_obs,
                Modularidade_obs,
                
                predator_sub,
                prey_sub,
                NODF_sub,
                Specialization_sub,
                Modularidade_sub)
    } else {
      outputb = c(n_network,
                 n,
                 predator_obs,
                 prey_obs,
                 NODF_obs,
                 Specialization_obs,
                 Modularidade_obs,
                 
                 predator_sub,
                 prey_sub,
                 NODF_sub,
                 Specialization_sub,
                 Modularidade_sub)
      output = rbind(output, outputb)
    }
  }

  output=as.data.frame(output)
  colnames(output)[1] <- "poll"
  colnames(output)[2] <- "name_sub_net"
  colnames(output)[3] <- "predator_observed"
  colnames(output)[4] <- "prey_observed"
  colnames(output)[5] <- "Aninhamento_observed"
  colnames(output)[6] <- "Specialization_observed"
  colnames(output)[7] <- "H2min_observed"
  colnames(output)[8] <- "H2max_observed"
  colnames(output)[9] <- "H2uncorr_observed"
  colnames(output)[10] <- "Modularidade_observed"
  
  colnames(output)[11] <- "predator_sub"
  colnames(output)[12] <- "prey_sub"
  colnames(output)[13] <- "Aninhamento_sub"
  colnames(output)[14] <- "Specialization_sub"
  colnames(output)[15] <- "H2min_sub"
  colnames(output)[16] <- "H2max_sub"
  colnames(output)[17] <- "H2uncorr_sub"
  colnames(output)[18] <- "Modularidade_sub"
  
  write.table(output,file = paste("poll_",n_network,"_output_theoretical_model.txt"), col.names=TRUE,row.names=FALSE,sep="\t")
  
  #next pool
  n_network=n_network+1
}


# Here you will use this output and select the data from each pool to plot a graph with x (sub-predator richness) against y (sub-metric).
# You can perform a simple linear regression with x and y. Plot that, and then with the points function, plot the observed value.
# After that, we can calculate a z-score or compute the distance between the network structures, which is similar to the z-score
# D = (mean(observed) - mean(simulated)) / sum(simulated). But since we're already using the z-score, we can just stick with it to make it easier
# when writing. Let me know if you have any questions.
# You can make this lm plot similar to the one in the article I sent you during the meeting.


# Perform linear regression for each pool and each metric
#load the data files
pool1 <- read.table("poll_ 1 _output_theoretical_model.txt", h=T)
pool2 <- read.table("poll_ 2 _output_theoretical_model.txt", h=T)
pool3 <- read.table("poll_ 3 _output_theoretical_model.txt", h=T)
pool4 <- read.table("poll_ 4 _output_theoretical_model.txt", h=T)
pool5 <- read.table("poll_ 5 _output_theoretical_model.txt", h=T)
pool6 <- read.table("poll_ 6 _output_theoretical_model.txt", h=T)
pool7 <- read.table("poll_ 7 _output_theoretical_model.txt", h=T)
pool8 <- read.table("poll_ 8 _output_theoretical_model.txt", h=T)
pool9 <- read.table("poll_ 9 _output_theoretical_model.txt", h=T)
pool10 <- read.table("poll_ 10 _output_theoretical_model.txt", h=T)
pool11 <- read.table("poll_ 11 _output_theoretical_model.txt", h=T)
pool12 <- read.table("poll_ 12 _output_theoretical_model.txt", h=T)
pool13 <- read.table("poll_ 13 _output_theoretical_model.txt", h=T)
pool14 <- read.table("poll_ 14 _output_theoretical_model.txt", h=T)
pool15 <- read.table("poll_ 15 _output_theoretical_model.txt", h=T)
pool16 <- read.table("poll_ 16 _output_theoretical_model.txt", h=T)
pool17 <- read.table("poll_ 17 _output_theoretical_model.txt", h=T)
pool18 <- read.table("poll_ 18 _output_theoretical_model.txt", h=T)
pool19 <- read.table("poll_ 19 _output_theoretical_model.txt", h=T)
pool20 <- read.table("poll_ 20 _output_theoretical_model.txt", h=T)
pool21 <- read.table("poll_ 21 _output_theoretical_model.txt", h=T)
pool22 <- read.table("poll_ 22 _output_theoretical_model.txt", h=T)

# Example scatterplot

# Model Construction example (ATTENTION you will need to change the metric and the pool number)
mod1 <- lm(Aninhamento_sub ~ prey_sub, pool1) # Constructing a linear regression model
cor(pool1$Aninhamento_sub, pool1$prey_sub) # Calculating the correlation coefficient
sd(pool1$Aninhamento_sub) # Calculating the standard deviation

# Check the model - graphical Analysis
check_model(mod1)
plot(mod1) # Visualizing the model's diagnostics plots:
# - Residuals vs Fitted: Checking linearity.
# - Normal Q-Q: Checking normality of residuals.
# - Scale-Location: Checking homoscedasticity.
# - Residuals vs Leverage: Detecting outliers and influential points.

# Model Analysis
summary(mod17) # Displaying summary statistics of the model, including R-squared.

# Plotting
nest_observed <- unique(pool1$Aninhamento_observed)
prey_observed <- unique(pool1$predator_observed)

p1 <- ggplot(data = pool1, mapping = aes(x = prey_sub, y = Aninhamento_sub)) +
  geom_point(alpha=1/9, size=5) +
  geom_point(mapping = aes(x = prey_observed, y = nest_observed),
             shape=17, col="blue", size=5) +
  labs(y="Nestedness", x="Number of preys") +
  geom_smooth(method = "lm", col = "red", se=T, fill = "grey", alpha=3/9, size=1.5) +
  scale_y_continuous(limits = c(0, 1)) +
  scale_x_continuous(breaks = seq(3, 10, by = 1)) +
  theme(axis.title.x = element_text(color="black", size = 30),
        axis.title.y = element_text(color="black", size = 30),
        axis.text = element_text(color="black", size = 28),
        legend.position = "none",
        plot.background = element_rect(fill='white', color=NA), # White plot background
        plot.margin = margin(.5,.8,.1,.5, "cm"),
        panel.grid.major = element_blank(), # Remove major gridlines
        panel.grid.minor = element_blank(), # Remove minor gridlines
        axis.line.y = element_line(color = "black"),
        axis.line.x = element_line(color = "black"),
        panel.background = element_rect(fill='white', colour = "black")) +
  annotate(geom="text", x=3,  y=0.25, hjust=0, size=6, color="black",
           label=paste0("R² = 0.85",
                        "\nSE = 0.0008",
                        "\nT = 988.6",
                        "\nP-value = <0.05***"))


# Calculate Z-scores for nestedness
zs_nestedness_pool1 <- (pool1$Aninhamento_observed[1] - mean(pool1$Aninhamento_sub)) / sd(pool1$Aninhamento_sub)

# Calculate Z-scores for modularity
zs_modularity_pool1 <- (pool1$Modularidade_observed[1] - mean(pool1$Modularidade_sub)) / sd(pool1$Modularidade_sub)

# Calculate Z-scores for specialization
zs_specialization_pool1 <- (pool1$Specialization_observed[1] - mean(pool1$Specialization_sub)) / sd(pool1$Specialization_sub)






